# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G6sBuZsaR64B6xkyy6T4jDsBLoVuOSZx
"""

import pandas as pd
import os
import numpy as np

from milestone1_func import get_game_ids_for_season, save_game_data_to_local, load_data_from_files
from feature_engineering_2 import add_features2

directory = "data"  # change this to your directory: run from root milestone2 dir


# LOAD DATA

'''
1. Acquire all of the raw play-by-play data for the 2015/16 season all the way to the 2019/20 season (inclusive)
2. Set aside all of the 2019/20 data as your final test set.
3. You will use the 2015/16 - 2018/19 regular season data to create your training and validation sets.
'''

# Load saved data into a pandas DataFrame
from feature_engineering_1 import tidy_data


tidied_file_path = os.path.join(directory, 'tidied_training_set_f2.csv')
test_file_path = os.path.join(directory, 'test_set_f2.csv')

if False and (os.path.exists(tidied_file_path) and os.path.exists(test_file_path)):
    tidied_training_set = pd.read_csv(tidied_file_path)
    test_set = pd.read_csv(test_file_path)
else:

    # DOESN'T DO ANYTHING IF FILES ALREADY EXIST
    download = False
    if download:
        # OJO: This needs the API
        seasons = ["20152016", "20162017", "20172018", "20182019", "20192020"]
        for season in seasons:
            game_ids = get_game_ids_for_season(season)
            save_game_data_to_local(game_ids, directory)
            print(f"Saved game data for season {season} to {directory}/game_id.json")

    data_list = load_data_from_files(directory)
    data = pd.DataFrame(data_list)

    # Add columns for season and game_type from gamePk
    data['season'] = data['gamePk'].apply(lambda x: str(x)[:4])
    data['game_type'] = data['gamePk'].apply(lambda x: str(x)[4:6])

    # TEST SET #########################

    # 2019-2020 season  # TODO: SHOULD WE KEEP ONLY game_type == '02' AS IN training_set?
    test_set = data[data['season'] == '2019'].copy()
    test_set.drop(['season', 'game_type'], axis=1, inplace=True)

    tidied_test_set = tidy_data(test_set)
    tidied_test_set = add_features2(tidied_test_set)
    tidied_test_set = tidied_test_set[tidied_test_set.eventTypeId.map(lambda t: t in {'SHOT', 'GOAL'})]

    dismiss = {'Winner_fullName',
       'Winner_link', 'Loser_fullName', 'Loser_link', 'team_link', 'team_triCode', 'Hitter_id',
       'Hitter_fullName', 'Hitter_link', 'Hittee_id', 'Hittee_fullName',
       'Hittee_link', 'Shooter_id', 'Shooter_fullName', 'Shooter_link',
       'Goalie_id', 'Goalie_fullName', 'Goalie_link', 'secondaryType',
       'PlayerID_id', 'PlayerID_fullName', 'PlayerID_link', 'Blocker_id',
       'Blocker_fullName', 'Blocker_link', 'PenaltyOn_id',
       'PenaltyOn_fullName', 'PenaltyOn_link', 'DrewBy_id', 'DrewBy_fullName',
       'DrewBy_link', 'ServedBy_id',
       'ServedBy_fullName', 'ServedBy_link', 'Scorer_id', 'Scorer_fullName',
       'Scorer_link', 'Assist_id', 'Assist_fullName', 'Assist_link'}

    # Save as csv
    tidied_test_set[[t for t in tidied_test_set.columns if t not in dismiss]].to_csv(test_file_path, index=False)

    # Save as csv
    # test_set.to_csv(test_file_path, index=False)

    # TRAINING AND VALIDATION SET

    # 2015/16 - 2018/19 regular season data
    train_seasons = {'2015', "2016", "2017", "2018"}
    training_set = data[(data['season'].isin(train_seasons)) & (data['game_type'] == '02')].copy()
    training_set.drop(['season', 'game_type'], axis=1, inplace=True)

    tidied_training_set = tidy_data(training_set)
    tidied_training_set = add_features2(tidied_training_set)
    tidied_training_set = tidied_training_set[tidied_training_set.eventTypeId.map(lambda t: t in {'SHOT', 'GOAL'})]

    # Save as csv
    tidied_training_set[[t for t in tidied_training_set.columns if t not in dismiss]].to_csv(tidied_file_path, index=False)



'''
# Uncomment to delete json files from directory (can use after saving data as csv)
# json files are around 2Gb size! 

file_list = os.listdir(directory)

json_files = [f for f in file_list if f.endswith(".json")]

for json_file in json_files:
    file_path = os.path.join(directory, json_file)
    os.remove(file_path)
    print(f"Deleted: {json_file}")
'''


"""#### 2. Feature Engineering I"""
# SEE feature_engineering_1.py

# OJO !
# checked https://www.nhl.com/gamecenter/nyi-vs-sjs/2015/10/17/2015020071/playbyplay
# and rink side is wrong ...


"""#### 4. Feature Engineering II (15% + bonus 5%)"""
# SEE feature_engineering_2.py


# here, tidied_training_set has all event types

# TODO: 2019 season has bad rink side. maybe some of gamePk, team, period, coordinates are wrong?












